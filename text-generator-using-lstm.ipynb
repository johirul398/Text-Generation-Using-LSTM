{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a964200d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-15T09:37:04.283899Z",
     "iopub.status.busy": "2023-03-15T09:37:04.283247Z",
     "iopub.status.idle": "2023-03-15T09:37:24.131501Z",
     "shell.execute_reply": "2023-03-15T09:37:24.129740Z",
     "shell.execute_reply.started": "2023-03-15T09:37:04.283849Z"
    },
    "papermill": {
     "duration": 0.006893,
     "end_time": "2023-04-05T14:27:52.527118",
     "exception": false,
     "start_time": "2023-04-05T14:27:52.520225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Introduction**\n",
    "\n",
    "Text generation refers to the process of using artificial intelligence algorithms to automatically generate natural language text. By generating large amounts of text data, machine learning algorithms can be trained to recognize patterns and relationships within language, which can then be used to develop more advanced NLP applications like chatbots and language translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d1970",
   "metadata": {
    "papermill": {
     "duration": 0.005096,
     "end_time": "2023-04-05T14:27:52.537888",
     "exception": false,
     "start_time": "2023-04-05T14:27:52.532792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1 Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1082e014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:27:52.550502Z",
     "iopub.status.busy": "2023-04-05T14:27:52.550037Z",
     "iopub.status.idle": "2023-04-05T14:28:00.145612Z",
     "shell.execute_reply": "2023-04-05T14:28:00.144488Z"
    },
    "papermill": {
     "duration": 7.605085,
     "end_time": "2023-04-05T14:28:00.148312",
     "exception": false,
     "start_time": "2023-04-05T14:27:52.543227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import nltk\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, LSTM, Dense, Input, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import string\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "           os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e781ce",
   "metadata": {
    "papermill": {
     "duration": 0.003631,
     "end_time": "2023-04-05T14:28:00.155883",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.152252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2 Load Dataset\n",
    "Here, I use nyt-comments dataset for text-generation and take only articles file and then extract only headlines columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fc13c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:28:00.165453Z",
     "iopub.status.busy": "2023-04-05T14:28:00.164809Z",
     "iopub.status.idle": "2023-04-05T14:28:00.406529Z",
     "shell.execute_reply": "2023-04-05T14:28:00.405493Z"
    },
    "papermill": {
     "duration": 0.249516,
     "end_time": "2023-04-05T14:28:00.409350",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.159834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_ap_17 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesApril2017.csv\")\n",
    "a_ap_18 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesApril2018.csv\")\n",
    "a_feb_17 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesFeb2017.csv\")\n",
    "a_feb_18 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesFeb2018.csv\")\n",
    "a_jan_17 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesJan2017.csv\")\n",
    "a_jan_18 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesJan2018.csv\")\n",
    "a_mr_17 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesMarch2017.csv\")\n",
    "a_mr_18 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesMarch2018.csv\")\n",
    "a_my_17 = pd.read_csv(\"/kaggle/input/nyt-comments/ArticlesMay2017.csv\")\n",
    "\n",
    "totaldata = pd.concat([a_ap_17,a_ap_18,a_feb_17,a_feb_18,a_jan_17,a_jan_18,a_mr_17,a_mr_18,a_my_17])\n",
    "\n",
    "data = totaldata.headline\n",
    "data = [i for i in data if i != \"Unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88212628",
   "metadata": {
    "papermill": {
     "duration": 0.003619,
     "end_time": "2023-04-05T14:28:00.416971",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.413352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3 Text Cleaning\n",
    "\n",
    "Text cleaning in NLP refers to the process of removing irrelevant information from text data for task. It typically involves many steps, including Removing non-alphabetic characters, Lowercasing and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa6c506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:28:00.426831Z",
     "iopub.status.busy": "2023-04-05T14:28:00.425863Z",
     "iopub.status.idle": "2023-04-05T14:28:00.469065Z",
     "shell.execute_reply": "2023-04-05T14:28:00.468163Z"
    },
    "papermill": {
     "duration": 0.050259,
     "end_time": "2023-04-05T14:28:00.471224",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.420965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaning(a):\n",
    "    a = (a).lower()\n",
    "    a = re.sub('[%s]' % re.escape(string.punctuation), '', a)\n",
    "    return a\n",
    "data = [cleaning(x) for x in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9686a3d",
   "metadata": {
    "papermill": {
     "duration": 0.003483,
     "end_time": "2023-04-05T14:28:00.478335",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.474852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4 Tokenization and Creating N_gram Sequences\n",
    "Tokenization is the process of converting text into a sequence of words or sub-words, known as tokens. In natural language processing, tokenization is a crucial step in preparing text data for further analysis or modeling. The Tokenizer class in the Keras library is a powerful tool for tokenizing text data. N-gram sequences are simply a sequence of N tokens in a row. They are used to represent the context of a word or phrase in a text sequence. To create n-gram sequences, we first tokenize the text data using the Tokenizer class in Keras. We then generate n-gram sequences by sliding a window of n words over the tokenized text and adding each window of words to a list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3997d2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:28:00.487214Z",
     "iopub.status.busy": "2023-04-05T14:28:00.486940Z",
     "iopub.status.idle": "2023-04-05T14:28:00.757332Z",
     "shell.execute_reply": "2023-04-05T14:28:00.756203Z"
    },
    "papermill": {
     "duration": 0.277907,
     "end_time": "2023-04-05T14:28:00.760153",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.482246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[381, 17],\n",
       " [381, 17, 5220],\n",
       " [381, 17, 5220, 511],\n",
       " [381, 17, 5220, 511, 4],\n",
       " [381, 17, 5220, 511, 4, 2],\n",
       " [381, 17, 5220, 511, 4, 2, 1573],\n",
       " [381, 17, 5220, 511, 4, 2, 1573, 139],\n",
       " [381, 17, 5220, 511, 4, 2, 1573, 139, 5],\n",
       " [381, 17, 5220, 511, 4, 2, 1573, 139, 5, 1930],\n",
       " [7, 69]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(data)\n",
    "total_words = len(token.word_index) + 1 \n",
    "Input = []\n",
    "for i in data:\n",
    "    token_list = token.texts_to_sequences([i])[0]\n",
    "    for j in range(1, len(token_list)):\n",
    "        n_gram = token_list[:j+1]\n",
    "        Input.append(n_gram)\n",
    "Input[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7495e05",
   "metadata": {
    "papermill": {
     "duration": 0.003769,
     "end_time": "2023-04-05T14:28:00.768129",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.764360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5 Padding and Separate Label (target) and Predictors (features)\n",
    "Padding in NLP refers to the process of adding zeros to the end of sequences or to the start of the sequences to make them all the same length. This is often necessary because neural networks require fixed-length inputs, and real-world text data typically varies in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b772e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:28:00.777262Z",
     "iopub.status.busy": "2023-04-05T14:28:00.776961Z",
     "iopub.status.idle": "2023-04-05T14:28:01.027047Z",
     "shell.execute_reply": "2023-04-05T14:28:01.025991Z"
    },
    "papermill": {
     "duration": 0.257675,
     "end_time": "2023-04-05T14:28:01.029673",
     "exception": false,
     "start_time": "2023-04-05T14:28:00.771998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = len(max(Input, key=len))\n",
    "Input = np.array(pad_sequences(Input, maxlen=max_sequence_len))\n",
    "predictors = Input[:,:-1]  #selects all the columns of the Input array except for the last column\n",
    "label = Input[:,-1] #elects only the last column of the Input array\n",
    "label =keras.utils.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35497ff",
   "metadata": {
    "papermill": {
     "duration": 0.003722,
     "end_time": "2023-04-05T14:28:01.037550",
     "exception": false,
     "start_time": "2023-04-05T14:28:01.033828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6 Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f24fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:28:01.046809Z",
     "iopub.status.busy": "2023-04-05T14:28:01.046454Z",
     "iopub.status.idle": "2023-04-05T14:28:03.795140Z",
     "shell.execute_reply": "2023-04-05T14:28:03.794260Z"
    },
    "papermill": {
     "duration": 2.765955,
     "end_time": "2023-04-05T14:28:03.807538",
     "exception": false,
     "start_time": "2023-04-05T14:28:01.041583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 23, 300)           3645000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               270600    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12150)             1834650   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,750,250\n",
      "Trainable params: 5,750,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_len = max_sequence_len - 1\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words,300, input_length=input_len))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d946b29",
   "metadata": {
    "papermill": {
     "duration": 0.004539,
     "end_time": "2023-04-05T14:28:03.816898",
     "exception": false,
     "start_time": "2023-04-05T14:28:03.812359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 7 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047d56a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:28:03.827960Z",
     "iopub.status.busy": "2023-04-05T14:28:03.827480Z",
     "iopub.status.idle": "2023-04-05T14:40:32.908649Z",
     "shell.execute_reply": "2023-04-05T14:40:32.907649Z"
    },
    "papermill": {
     "duration": 749.847324,
     "end_time": "2023-04-05T14:40:33.669293",
     "exception": false,
     "start_time": "2023-04-05T14:28:03.821969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1620/1620 [==============================] - 29s 14ms/step - loss: 7.8775\n",
      "Epoch 2/70\n",
      "1620/1620 [==============================] - 11s 7ms/step - loss: 7.2662\n",
      "Epoch 3/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 6.7421\n",
      "Epoch 4/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 6.1604\n",
      "Epoch 5/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 5.5143\n",
      "Epoch 6/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 4.8412\n",
      "Epoch 7/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 4.2013\n",
      "Epoch 8/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 3.5934\n",
      "Epoch 9/70\n",
      "1620/1620 [==============================] - 11s 7ms/step - loss: 3.0774\n",
      "Epoch 10/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 2.6192\n",
      "Epoch 11/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 2.2628\n",
      "Epoch 12/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.9596\n",
      "Epoch 13/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.7245\n",
      "Epoch 14/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.5362\n",
      "Epoch 15/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.3810\n",
      "Epoch 16/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.2626\n",
      "Epoch 17/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.1634\n",
      "Epoch 18/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.0836\n",
      "Epoch 19/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 1.0178\n",
      "Epoch 20/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.9738\n",
      "Epoch 21/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.9282\n",
      "Epoch 22/70\n",
      "1620/1620 [==============================] - 11s 6ms/step - loss: 0.8899\n",
      "Epoch 23/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.8611\n",
      "Epoch 24/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.8426\n",
      "Epoch 25/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.8176\n",
      "Epoch 26/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7947\n",
      "Epoch 27/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7831\n",
      "Epoch 28/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7808\n",
      "Epoch 29/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7579\n",
      "Epoch 30/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7477\n",
      "Epoch 31/70\n",
      "1620/1620 [==============================] - 11s 7ms/step - loss: 0.7420\n",
      "Epoch 32/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7341\n",
      "Epoch 33/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7223\n",
      "Epoch 34/70\n",
      "1620/1620 [==============================] - 11s 6ms/step - loss: 0.7161\n",
      "Epoch 35/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7134\n",
      "Epoch 36/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7041\n",
      "Epoch 37/70\n",
      "1620/1620 [==============================] - 11s 7ms/step - loss: 0.7030\n",
      "Epoch 38/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.7006\n",
      "Epoch 39/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6945\n",
      "Epoch 40/70\n",
      "1620/1620 [==============================] - 11s 7ms/step - loss: 0.6886\n",
      "Epoch 41/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6824\n",
      "Epoch 42/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6797\n",
      "Epoch 43/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6802\n",
      "Epoch 44/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6741\n",
      "Epoch 45/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6760\n",
      "Epoch 46/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6695\n",
      "Epoch 47/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6664\n",
      "Epoch 48/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6666\n",
      "Epoch 49/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6598\n",
      "Epoch 50/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6586\n",
      "Epoch 51/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6596\n",
      "Epoch 52/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6586\n",
      "Epoch 53/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6561\n",
      "Epoch 54/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6510\n",
      "Epoch 55/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6514\n",
      "Epoch 56/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6490\n",
      "Epoch 57/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6469\n",
      "Epoch 58/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6457\n",
      "Epoch 59/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6443\n",
      "Epoch 60/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6457\n",
      "Epoch 61/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6436\n",
      "Epoch 62/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6402\n",
      "Epoch 63/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6371\n",
      "Epoch 64/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6369\n",
      "Epoch 65/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6379\n",
      "Epoch 66/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6361\n",
      "Epoch 67/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6370\n",
      "Epoch 68/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6297\n",
      "Epoch 69/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6288\n",
      "Epoch 70/70\n",
      "1620/1620 [==============================] - 10s 6ms/step - loss: 0.6342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7128d1e3fe10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, label, epochs=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20b77f",
   "metadata": {
    "papermill": {
     "duration": 0.749767,
     "end_time": "2023-04-05T14:40:35.122433",
     "exception": false,
     "start_time": "2023-04-05T14:40:34.372666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8 Define Function to Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbec60a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:36.573562Z",
     "iopub.status.busy": "2023-04-05T14:40:36.573192Z",
     "iopub.status.idle": "2023-04-05T14:40:36.580396Z",
     "shell.execute_reply": "2023-04-05T14:40:36.579310Z"
    },
    "papermill": {
     "duration": 0.757851,
     "end_time": "2023-04-05T14:40:36.582639",
     "exception": false,
     "start_time": "2023-04-05T14:40:35.824788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, token, max_sequence_len):\n",
    "    #seed_text = input(\"Enter some text: \")\n",
    "    seed_text = \"President Donald Trump\"\n",
    "    #next_words = int(input(\"Enter the number of words to generate: \"))\n",
    "    next_words = 5\n",
    "    for _ in range(next_words):\n",
    "        token_list = token.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        \n",
    "        predicted = np.argmax(predicted_probs) + 1\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in token.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a21a53a",
   "metadata": {
    "papermill": {
     "duration": 0.772862,
     "end_time": "2023-04-05T14:40:38.055158",
     "exception": false,
     "start_time": "2023-04-05T14:40:37.282296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 9 Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff742ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-05T14:40:39.540459Z",
     "iopub.status.busy": "2023-04-05T14:40:39.539501Z",
     "iopub.status.idle": "2023-04-05T14:40:40.286897Z",
     "shell.execute_reply": "2023-04-05T14:40:40.285837Z"
    },
    "papermill": {
     "duration": 1.466787,
     "end_time": "2023-04-05T14:40:40.289083",
     "exception": false,
     "start_time": "2023-04-05T14:40:38.822296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated text is :  President Donald Trump To War Is Their Trivia\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_text(model, token, max_sequence_len)\n",
    "print(\"The generated text is : \",generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 781.309865,
   "end_time": "2023-04-05T14:40:44.977576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-05T14:27:43.667711",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
